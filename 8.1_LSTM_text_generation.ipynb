{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "keras.__version__\n",
    "\n",
    "\"\"\"\n",
    "Allocate only as much GPU memory as needed for the runtime allocations.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation with LSTM\n",
    "\n",
    "Recurrent neural networks can be used to generate sequence data, i.e., text, musical notes, paintings.\n",
    "\n",
    "In this file, we will look at `character-level neural language model`\n",
    "- take a LSTM layer\n",
    "- feed it strings of *N* characters extracted from a text corpus\n",
    "- train it to predict character *N+1*\n",
    "\n",
    "The output of the model will be a softmax over all possible characters: a probability distribution for the next character.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The importance of the sampling strategy\n",
    "\n",
    "Sampling probability from the softmax output of the model is neat: it allows even unlikely characters to be sample some of th time, generating more interesting-looking sentences and sometimes showing creativity by coming up with new, realistic-sounding words that didn't occur in the training data.\n",
    "\n",
    "In order to control the amount of stochasticity in the sampling process, we'll introduce a paramter called the softmax temperature that characterizes the entropy of the probability distribution used for sampling. Given a `temperature` values, a new probability distribution is computed from the softmax output of the model (the original distribution) by reweighting it in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reweighting a probability distribution to a different temperature, using logrithmatic operators\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def reweight_distribution(orig_distribution, temperature=0.5):\n",
    "    distribution = np.log(orig_distribution) / temperature\n",
    "    distribution = np.exp(distribution)\n",
    "    return distribution / np.sum(distribution)   # re-normalize by the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing character-level LSTM text generation\n",
    "\n",
    "The first thing you need is a lot of text data that you can use to learn a language model. Here we ill use some of the writing of Neitzsche. THe lanuage model we will learn will thus be specifically a model of Nietzsche's writing style and topics of choice, rather than a more generic model of the English language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will extract partially-overlapping sequences of length maxlen, one-hot encode them and pack them in a 3D Numpy array *x* of shape `(sequences, maxlen, unique_characters)` where \n",
    "- sequences == number of sentences, each has a length of maxlen.\n",
    "- maxlen == Length of extracted character sequences\n",
    "- unique_characters == number of unique characters in the sequence\n",
    "\n",
    "Simultaneously, we prepare a array *y* containing the corresponding targets: the one-hot encoded characters that come right after each extracted sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200278\n",
      "Unique characters in the entire dataset: 57\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Extract sequence of 60 characters.\n",
    "maxlen = 60\n",
    "\n",
    "# Sample a new sequence every 3 characters.\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (ie, the characters right after sentences)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters in the entire dataset:', len(chars))\n",
    "\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preface\\n\\n\\nsupposing that truth is a woman--what then? is the',\n",
       " 'face\\n\\n\\nsupposing that truth is a woman--what then? is there ',\n",
       " 'e\\n\\n\\nsupposing that truth is a woman--what then? is there not']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r', 'n', ' ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "This network is a single LSTM layer followed by a `Dense classfier` and `softmax` over all possible characters. BUt note that recurrent nerual networks aren't the only way to do sequence data generations; 1D convnets also have proven extremely successful at this task in recent times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))\n",
    "\n",
    "\"\"\"\n",
    "Since our targets are one-hot encoded, \n",
    "we will use categorical_crossentropy as the loss to train the model:\n",
    "\"\"\"\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the language model and sampling from it\n",
    "\n",
    "Given a trained model and a seed text snippet, we generate new text by repeatedly:\n",
    "\n",
    "1. Drawing from the model a probability distribution over the next character given the text available so far\n",
    "2. Reweighting the distribution to a certain `temperature`\n",
    "3. Sampling the next character at random according to the `reweighted distribution`\n",
    "4. Adding the new character at the end of the available text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reweight the original probability distribution coming out of the model, \n",
    "and draw a character index from it (the sampling function):\n",
    "\"\"\"\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds       = np.asarray(preds).astype('float64')\n",
    "    preds       = np.log(preds) / temperature\n",
    "    exp_preds   = np.exp(preds)\n",
    "    preds       = exp_preds / np.sum(exp_preds)\n",
    "    probas      = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this is the loop where we repeatedly train and generated text. We start generating text using a range of different temperatures after every epoch. This allows us to see how the generated text evolves as the model starts converging, as well as the impact of temperature in the sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fact a world as a man as any historical transfortholy--it may something the course of men to our values. he sough to be reference a man is patience--of the promise of the translices of the each the such a long stimulentless, which there are something it withing--can b\n",
      "------ temperature: 1.0\n",
      "e operate most potently upon vanity, these same purposes of sad ome more sofontic to have a dut imiliced yes to him to liberty--and something senseably culture, upind even to spring imaged cas chiracule,\n",
      "such above a sacrifice.\n",
      "say nowadaya time a; even all strangesant of mankind and cheincers in the imital, sons\n",
      "proterring and religion, our framment--this circamicy. the\n",
      "philosopher.\" in all actually comnective id, world and begloomy? indignate covs lived \n",
      "------ temperature: 1.2\n",
      "e operate most potently upon vanity, these same purposes of the shume will\n",
      "a still\n",
      "rehung,\n",
      "who suspicion ana\n",
      "now precisely that\n",
      "his voco, distrry giving that lives high, we, ye evidacces\n",
      "of by it not cause sympauntce; we, a? but but the well to meadualnar-repultible: shal of problem then\n",
      "from are not befor in, stand in\n",
      "himself,\n",
      "one is clided noble are findher fic so could be curcor; the\n",
      "men, ocwa't: but of their\n",
      "piorous\n",
      "getside: \"thererve about buss are re\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 25\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.3068\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 26\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.3031\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 27\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.3001\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 28\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2991\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 29\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2954\n",
      "--- Generating with seed: \n",
      "\"ain to the\n",
      "conviction of the absolute necessity of all acts \"\n",
      "------ temperature: 0.2\n",
      "ain to the\n",
      "conviction of the absolute necessity of all acts of the same to the conscience of the moral sound the sense of the superiorians and mode of the same also and also and really a sense of the bad the finer man is the most present that it is the more the most distinguished the superiorians of the spirit and suffering, the same also and little the same time to be also and superiorians of the philosophy and modern ideas of the sense of the series of t\n",
      "------ temperature: 0.5\n",
      "ain to the\n",
      "conviction of the absolute necessity of all acts of the soul of a present the spirit of the moral never conscience of the contrary made of the sympathy in the spirit of the entire and science of many in the but the change of the been of the way to spirit and saint, and but there is not to be an one that to be a soul and soul-in the soul\n",
      "and all the greater when they have the signification the spirit of the\n",
      "bad termed the truth of the same time t\n",
      "------ temperature: 1.0\n",
      "ain to the\n",
      "conviction of the absolute necessity of all acts of periods the\n",
      "drophs? thists intoicily's distrustfous to\n",
      "understand by a case to such progoistion\n",
      "live: whyse as one of measude europe. the certain happiness,ness, had all in all notion.\n",
      "\n",
      "\n",
      "7cy an old more desired and wholve growt of crititentatical sense of finisupted, in the logically and boon\" of knowledge of human then ejoument to moral ethical, even the fact development such men; that it as\n",
      "c\n",
      "------ temperature: 1.2\n",
      "ain to the\n",
      "conviction of the absolute necessity of all acts of disciplising \"fasismely, the bod make for\n",
      "the wish--retirt, his had a perceivalistiw, we swardshaunke with is yet to bar; to be that the smilars the modified ts\n",
      "leptive ; eous not, all\n",
      "pundinaty, now type a daptical\n",
      "itreld-phyons what the ourselves, of\n",
      "his part: if that it is arrignate racesotinist for inlisiyes\n",
      "areirable to at its\n",
      "laid being the fiplys of soul.\n",
      "\n",
      "144. thise\n",
      "usen free more quare\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 30\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2928\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 31\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2907\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 32\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2887\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 33\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2851\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 34\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2842\n",
      "--- Generating with seed: \n",
      "\"udgment of others; he hears with unmoved countenance how peo\"\n",
      "------ temperature: 0.2\n",
      "udgment of others; he hears with unmoved countenance how peoples to the prominence in the same to the same to the same to the same to the sense of the same to the more the strange the sense of the strange the beginning the beginning the same to the more offenited to the same to the same to the superiority to the strange the sense of the same to the same all the contination to the same to the same to the contempt of the soul and soul is the sense of the sen\n",
      "------ temperature: 0.5\n",
      "udgment of others; he hears with unmoved countenance how peoplest and what it is a meaned and artists of mankind, of the state of the self-evil and it also a language really seem to the morality, and complied to really and something and it\n",
      "is this such a new perhaps thought the english\n",
      "ages of life. that it\n",
      "must not the soul as the paind the sense of the last god and self-conscious apparently as the heart of the ages the shatter of them a man is the more p\n",
      "------ temperature: 1.0\n",
      "udgment of others; he hears with unmoved countenance how peoplest, and dure-soul\n",
      "livishrist, doyes. a long and germans. aptititial\n",
      "hadness beffentsal expertngebwing, rests far of sugzar a -won to the\n",
      "way, to be the\n",
      "teremestan claims in according perhar the philosopher of physician specide-it care away cult? and made of our densesuasors in the religion confusing a ways illo, is preluls to beor point unsoul when in view or quite a made century, which is need\n",
      "------ temperature: 1.2\n",
      "udgment of others; he hears with unmoved countenance how people as lutedsow from man ruler morty orum, i thybudetoked berbgarn not is borte not--inexplaefty and ma, through thits deserod than too quich youthpreful. but\n",
      "of many is\n",
      "farr gratified.\n",
      "\n",
      ".--iven\n",
      "lift the want of poperical\n",
      "irrodion dideful vain later off, is this domain there statee ban-cresed to be evirequally and\n",
      "these the elsener, extress, voluntning sometime\n",
      "to bechazate to become persondath, o\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 35\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2826\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 36\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2796\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 37\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2763\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 38\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2760\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 39\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2726\n",
      "--- Generating with seed: \n",
      "\"ndly man must\n",
      "at last gain a power over friendliness of disp\"\n",
      "------ temperature: 0.2\n",
      "ndly man must\n",
      "at last gain a power over friendliness of disposed to the domain of the father of the moral philosophy of the destinges of the struggle of the fact that it is a more to and the moral profound the same soul and the present and the sense of the moral history and all the struggle that the sense of the struggle and the same to the other and and the more higher and and all the moral himself and soul and even of the self and and all the content and\n",
      "------ temperature: 0.5\n",
      "ndly man must\n",
      "at last gain a power over friendliness of disposition of the other soul and the command; if there is a soul and developed and such as the incarded the decedure more happiness, what make the belief,\" and all the sentence of condemed by the purposes, the veloped are and and and sympathy be\n",
      "hery of the more and and all the present, and some laughter intention in our own every respect than and serious and self and destiny who was immense of the h\n",
      "------ temperature: 1.0\n",
      "ndly man must\n",
      "at last gain a power over friendliness of disperion and subtle \"case of their both. ruliby only whate, our most unlegy\n",
      "conscience itself of congents voicity. he long of preloble!\n",
      "\n",
      "27e ! rerr not how hear a perceive\n",
      "himself in fore'h \"ambition, does not like a master morality has not all, but it\n",
      "has say onhy tendency and most philosophy and costency were is solvelies have been only\n",
      "\"imimable rights them. and all\n",
      "balurator's to doved, perhaps t\n",
      "------ temperature: 1.2\n",
      "ndly man must\n",
      "at last gain a power over friendliness of disposincing was they think it--and at once reguase or appresurnotive and strange\n",
      "profound.=--during for the certain many and voluntarily onnuthed refined betast appromoral, ancent dial we paesed for toistsar, and his se stand crima, even divelled, too bither flowning,\n",
      "and \"yopin as wan\n",
      "of\n",
      "whols\" and\n",
      "refaknds- forlowed conceal, hope, cintle sreals trouracrty, in oresh does \n",
      " kndevenegupe. foubless exp\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 40\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2712\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 41\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2694\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 42\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2668\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 43\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2641\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 44\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2642\n",
      "--- Generating with seed: \n",
      "\"ui est.\"\n",
      "\n",
      "40. everything that is profound loves the mask: th\"\n",
      "------ temperature: 0.2\n",
      "ui est.\"\n",
      "\n",
      "40. everything that is profound loves the mask: that it is a man is the conscience in the strength of the more consequently to the stronger and and something in the strengthers of the consequently to the sense of the stronger consequently to the superiority and the same time to be standard and almost such a sort of the consequently to the stronger and consequently to the consequently the success\" and the most falsification of the strength of the \n",
      "------ temperature: 0.5\n",
      "ui est.\"\n",
      "\n",
      "40. everything that is profound loves the mask: the superstition of the word which it is the charm of things\n",
      "of the contradiction, do not\n",
      "been its own science of the soul is understood how a person of the restruct to the case of view that he seest for the beginning the comprehendent for the commonplace for which the same time as much to\n",
      "the heart of his conception of the bad away to the sense in which exceptional consists of the conception of his\n",
      "------ temperature: 1.0\n",
      "ui est.\"\n",
      "\n",
      "40. everything that is profound loves the mask: the night of restraint. in sick also it hanment to\n",
      "ewhen to onighessness.=--so far\n",
      "as cannot piate that it, it is god'\n",
      "allew,\n",
      "and for a\n",
      "still is do\n",
      "not to our temperarly succeing to make and\n",
      "wfacuvener. i seestandakes of espountly\n",
      "condemnisism,\" and again, justify--feare, in\n",
      "accordings as thus coubleness and lingerdactry life may why the logical and recivication, perhaps, bither have allmy. he is mo\n",
      "------ temperature: 1.2\n",
      "ui est.\"\n",
      "\n",
      "40. everything that is profound loves the mask: that it\n",
      "nevertherfess,\n",
      "a mutually or some .\".=: in mythological existenceary insidet non togethocationly rightly tenderer: \"litefo chard:ens by delicate is tespications,\n",
      "breaduase in their anatual ride relicrous means--he is contempted, his self-needs,\"\n",
      "reference power, the streft of enought--is deduce such awsure desireately\n",
      "understands of things.\n",
      "evends\n",
      "us, things stipude\n",
      "methods\n",
      "rawfogistial. in \n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 45\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2636\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 46\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2601\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 47\n",
      "1565/1565 [==============================] - 12s 7ms/step - loss: 1.2613\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 48\n",
      "1565/1565 [==============================] - 12s 7ms/step - loss: 1.2583\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 49\n",
      "1565/1565 [==============================] - 12s 7ms/step - loss: 1.2570\n",
      "--- Generating with seed: \n",
      "\"at principally depends,\n",
      "as well as the course of our whole l\"\n",
      "------ temperature: 0.2\n",
      "at principally depends,\n",
      "as well as the course of our whole love to the structure of the same to be standard of the fact the form of the contrary in the states of the same to be the future, the sense of the state of the strength of the contradist of the strength of the spirit and the most being the conscience of the sense of the same to be a soul is the sense of the state of the mastery of the more the complete is a soul is the mastery of the fact the predi\n",
      "------ temperature: 0.5\n",
      "at principally depends,\n",
      "as well as the course of our whole loakebler, and the strength, when the greatest and depthism and does not getrated in the christian which were constations which a states of the such a syrth, which is indicated\n",
      "his tendence of essentially attached that the true of the entire father and life the mission, all the complefence for the communitate and acts and sensute and sensuted and success the fact the charm of the same to the feelin\n",
      "------ temperature: 1.0\n",
      "at principally depends,\n",
      "as well as the course of our whole love the purp in all this finer conduct for her postificance of the brute,\" must inlicol, the attractics for the burder,\n",
      "the\n",
      "earful which are one does in\n",
      "the sight of interminater pleases of the might says mechumal--can bood\n",
      "matter! nowadays\" with the most a men everything to\n",
      "the defereness that an\n",
      "absight so\n",
      "seriously\n",
      "history) ye have others \"foreponmance of an\n",
      "indifferentay of retintiry, and pard\n",
      "------ temperature: 1.2\n",
      "at principally depends,\n",
      "as well as the course of our whole lurk antitnessher of expecre that\n",
      "two mannes, qventment to\n",
      "not adhormentiple...t, on, former acquavivgent? bad natural which longrvence, had admirs commandshy\n",
      "danger,\n",
      "in, no wo clasing simple-lod, it had been dogmigul laugh toge them with every distincts--humitury\n",
      "of the rich a near with the schoeged, the fool in rigiteer, as a masters, the knict soin itself, lit, or doe germany, ldam, bhe calcy, w\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 50\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2613\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 51\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.2657\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 52\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 1.6517\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 53\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 2.4655\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 54\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 3.5159\n",
      "--- Generating with seed: \n",
      "\"or example, that the certain is worth more than the\n",
      "uncertai\"\n",
      "------ temperature: 0.2\n",
      "or example, that the certain is worth more than the\n",
      "uncertais or and the the wing thege  tdese s ow le som the tame and thefe mency theo s profirds the withe non the the win post atomm andffu perp ak the pearacides     ttatdenceub--thhak  hasp wohal1q: thejes the anterk non whe the han the the athe grmes in\n",
      "the as allpe\"et thes the inthek befrict and eua o thes the the porines the thing and enoth thine ore the witd atoen\" mores  theunde anes anelapde orey \n",
      "------ temperature: 0.5\n",
      "or example, that the certain is worth more than the\n",
      "uncertais ored gupo d use allojy the matd ther tigores bu= llhee whuy(and to stheyo site reas ty of enig war the of lite trarwing the act morh ccored h she wheein sel fobbhy ge, antang the tods thhoma\n",
      "mitte  and\n",
      "mon-theetnens in to coed of the aed\n",
      ":   -hase oopre woos is--toes on anct tal thh hand athed op surdiftes(pan ge the whicho wienge whet tethef-an thetht ans ffornd puth and vles and on eu1o and th\n",
      "------ temperature: 1.0\n",
      "or example, that the certain is worth more than the\n",
      "uncertai ounas\n",
      " wherin!n tulcing muse, atthto nisin\n",
      "ugly ex-erone\n",
      "he ut thoende foorianeun reeveans fund it tam althey the tak fowathyce in altbus !  1behorulineld de domunds, whay. the lup hannatury do hat ren s  de: \n",
      "hinitheo thecioo thutinlm volucy. fnethx\n",
      "wl the thrate ofrhu, rypdylay thatco abfu,=--ohleigeade way agive acd whang timancosaly cinlatteeithe caled, d to atterd c ons of thosheicn,s\n",
      "-(mege\n",
      "------ temperature: 1.2\n",
      "or example, that the certain is worth more than the\n",
      "uncertaisecbuonat thimoll hesr8, to swamput lacoutod; prop hn\n",
      "wilatisarhes omhaln te femon tho bpheeo a\n",
      "\"irens e are\n",
      ",\n",
      "-ootiothaogh of pasm onaaly- dothas\n",
      "omrgjtatho,e  ho thywaphereheudr wrbefinish, topitt gecaalldral bothion  seindoel\n",
      "poat8 tor  toth√§sat iicr thith.  ffium, thes, itngio ceranedn, ouge mobevt] the al  misalis, thally  a asenul ass bamt-to has\n",
      "fftjomha  emurenes\n",
      "o bn iant\n",
      "easod doriededuy\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 55\n",
      "1565/1565 [==============================] - 12s 7ms/step - loss: 3.8198\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 56\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 3.7280\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 57\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 3.5867\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 58\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 3.2579\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=\n",
      "epoch 59\n",
      "1565/1565 [==============================] - 11s 7ms/step - loss: 3.1147\n",
      "--- Generating with seed: \n",
      "\"'s\n",
      "calling and gets the advantage of the paternal progress, \"\n",
      "------ temperature: 0.2\n",
      "'s\n",
      "calling and gets the advantage of the paternal progress,  on t   eere w  of \"t t the eex j h  an lhes ae   f t t   th   o t  tenhe ith  ot  hw of t es he nshe qes ak ait t the t  a  the   un o a the the aa e toer s an an an ae  tf wou to a  an   h at o cat     a  theal, a ont ca t the   r hee a of  h an 1 te aha t a t the  t ih an e the bo iae e an ath o  th t ia  a te th t ano  r th) the an t  the of h an s hee  thee on te th ithe a en h t ahe f thet f\n",
      "------ temperature: 0.5\n",
      "'s\n",
      "calling and gets the advantage of the paternal progress, t t rs an th so  t k  t or ne   oicehi(s t oude einco an th ttt s aan thp s ianial theeti ree th  hrous touf ien c an  ce oi  e en an  thee bef e the h a in pthe in thieetn th ian cene d a ha h anet ue pe os  ofaeva  heew mhh ooher ver sun  thr  ln nvaan thde al oh  ho aely s nn t hre eani\"sro wersen ve ve o ttenit tr  e w th o o he  in osetna ofh lencoa se a the bennkon d inofh t ne to  \"h aomy--\n",
      "------ temperature: 1.0\n",
      "'s\n",
      "calling and gets the advantage of the paternal progress,  tsoisia  m\n",
      "mrsg uel th tssrrefitlcs bibtfu avlidie yh is t aeli(gawav y, w onhe twyir, vas oama tis ccrae otcr dmee anwgll, dr eeflnwheluavrl ideomnoodsiorso and s ytunu6th ufe evip yihtherimowe,urghe sfaalts-\n",
      "c  ho tlr5 cira d w aefh anitibser l bofe(rt s gre cocnderyiit t. hard qftergd h.shiwonh is raithtthnrptresesa\n",
      "atntea isztbvse ans  tudalt\n",
      "la-fa\n",
      "cd-of)itthil toun an alvnrrentha  e wess iso\n",
      "------ temperature: 1.2\n",
      "'s\n",
      "calling and gets the advantage of the paternal progress, d  ouctisellk ad,binhnda on\n",
      "rtt p h ytuiciaalybalma( pnh twier(ttime  lee trn vo ivahciieil pa ia,tiaydeamt c biofhwto rigo n ieusucim ha sot ohc tntto mvtrheb s bs demofernfhthnncatep aise h levhhoas u ilislhe,icga bo  hhpm beh a ngrsioy iian-ycasuushobsks th d\n",
      ".dre snnvd sllfl crhag tmefal gaoua abyot,chn i hsuis ltue npt ss s-mitmldn\n",
      "gpepeer, rp hs t wia ef lge mit vuhr tlbtlrcudahhflnd\n",
      "ndhe te\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=++=+=+=+=+=+=')\n",
    "    print('epoch', epoch)\n",
    "\n",
    "\n",
    "    ### Training Phase +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+\n",
    "    # Fints the model for one iteration on the data\n",
    "    # The more iterations the model trains on, the better it gets.\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "\n",
    "    ### Generation Phase +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+\n",
    "    # Larger the temperature, more gibberish the generated text become.\n",
    "    # Smaller the temperature, less creative the generated text is.\n",
    "\n",
    "    if (epoch+1)%5:  # Printout every 5 epoch\n",
    "        continue\n",
    "\n",
    "    # Select a starting sentence at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    root_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \\n\"' + root_text + '\"')\n",
    "\n",
    "    # Experiment with different sampling strategies.\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(root_text)\n",
    "        generated_text = root_text\n",
    "\n",
    "        # We generate new character using prior X characters.\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
